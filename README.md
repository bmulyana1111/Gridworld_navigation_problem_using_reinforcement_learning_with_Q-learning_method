The QLearning class encapsulates the Q-learning algorithm. 
The constructor initializes the Q-table with all values set to zero, and the class provides methods to get the best action for a given state, choose an action using epsilon-greedy exploration, update the Q-table, decay the exploration rate, and print the Q-table.
The main function defines the problem space (a gridworld with a specific size), creates an instance of the QLearning agent, and runs the Q-learning loop for a specified number of episodes. In each episode, the agent starts in a random state and performs actions until reaching the terminal state. The agent chooses actions using epsilon-greedy exploration, updates the Q-table based on the observed reward and next state, and decays the exploration rate. Finally, the learned Q-table is printed.
